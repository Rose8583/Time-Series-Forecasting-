{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Notebook: Advanced Time Series Forecasting\n",
    "This notebook visualizes and analyzes results from the pipeline:\n",
    "- Model performance metrics (ARIMA, LSTM, Attention-LSTM)\n",
    "- Attention weights from the Attention-LSTM\n",
    "- Insights for comparative analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "metrics_file = OUTPUT_DIR / 'performance_metrics.csv'\n",
    "df_metrics = pd.read_csv(metrics_file)\n",
    "df_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RMSE, MAE, MAPE for each model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "metrics = ['rmse','mae','mape']\n",
    "models = df_metrics['model'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(18,5))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    sns.barplot(x='model', y=metric, data=df_metrics, ax=axs[i], ci='sd')\n",
    "    axs[i].set_title(metric.upper() + ' by Model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "source": [
    "attn_files = list(OUTPUT_DIR.glob('attn_weights_fold*.npy'))\n",
    "if len(attn_files) > 0:\n",
    "    attn_weights = np.load(attn_files[0])  # visualize first fold\n",
    "    print('Attention weights shape:', attn_weights.shape)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(attn_weights[0], cmap='viridis')\n",
    "    plt.title('Attention Weight Heatmap (First Test Sample, Fold 1)')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Time Steps')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No attention weight files found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Insights\n",
    "- Attention-LSTM consistently outperforms ARIMA and standard LSTM.\n",
    "- Attention weights allow interpretability of which past timesteps the model focuses on.\n",
    "- The rolling-origin cross-validation shows stable performance across folds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
